{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REGRESSÃO LOGÍSTICA BINÁRIA COM VARIÁVEIS EXPLICATIVAS QUANTI E QUALIS\n",
    "\n",
    "EXEMPLO 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importação dos pacotes\n",
    "import pandas as pd # manipulação de dados em formato de dataframe\n",
    "import numpy as np # operações matemáticas\n",
    "import seaborn as sns # visualização gráfica\n",
    "import matplotlib.pyplot as plt # visualização gráfica\n",
    "from scipy.interpolate import UnivariateSpline # curva sigmoide suavizada\n",
    "import statsmodels.api as sm # estimação de modelos\n",
    "import statsmodels.formula.api as smf # estimação do modelo logístico binário\n",
    "from statstests.process import stepwise # procedimento Stepwise\n",
    "from scipy import stats # estatística chi2\n",
    "import plotly.graph_objects as go # gráficos 3D\n",
    "from statsmodels.iolib.summary2 import summary_col # comparação entre modelos\n",
    "from statsmodels.discrete.discrete_model import MNLogit # estimação do modelo\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score,\\\n",
    "    ConfusionMatrixDisplay, recall_score\n",
    "                                                        #logístico multinomial\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> continuar em 1'48\n",
    "https://class.movelms.com/class_v2?t=ce05483a753eb5f36d381d6273634b0e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fidelidade = pd.read_csv('/home/usp_ds_analytics/logistic_models/data/dados_fidelidade.csv',delimiter=',')\n",
    "df_fidelidade.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Características das variáveis do dataset\n",
    "df_fidelidade.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estatísticas univariadas\n",
    "df_fidelidade.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[3.1]: Alteração dos tipos das variáveis não quantitativas no dataframe\n",
    "\n",
    "# Transformação do 'id' para o tipo 'str'\n",
    "df_fidelidade['id'] = df_fidelidade['id'].astype('str')\n",
    "\n",
    "# Transformação das variáveis explicativas qualitativas para o tipo 'object'\n",
    "df_fidelidade['atendimento'] = df_fidelidade['atendimento'].astype('object')\n",
    "df_fidelidade['sortimento'] = df_fidelidade['sortimento'].astype('object')\n",
    "df_fidelidade['acessibilidade'] = df_fidelidade['acessibilidade'].astype('object')\n",
    "df_fidelidade['preço'] = df_fidelidade['preço'].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Características das variáveis do dataset\n",
    "df_fidelidade.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estatísticas univariadas\n",
    "df_fidelidade.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[3.2]: Tabela de frequências absolutas das variáveis qualitativas referentes\n",
    "#aos atributos da loja na percepção dos consumidores\n",
    "df_fidelidade['fidelidade'].value_counts().sort_index()\n",
    "df_fidelidade['sexo'].value_counts().sort_index()\n",
    "df_fidelidade['atendimento'].value_counts().sort_index()\n",
    "df_fidelidade['sortimento'].value_counts().sort_index()\n",
    "df_fidelidade['acessibilidade'].value_counts().sort_index()\n",
    "df_fidelidade['preço'].value_counts().sort_index()\n",
    "\n",
    "# In[3.3]: Note que a variável Y 'fidelidade' está definida como objeto\n",
    "#(PROBLEMA!!!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformando a variável Y para 0 e 1 e para o tipo 'int' (poderia também\n",
    "#ser do tipo 'float'), a fim de que seja possível estimar o modelo por meio\n",
    "#da função 'sm.Logit.from_formula'\n",
    "\n",
    "df_fidelidade.loc[df_fidelidade['fidelidade']=='sim', 'fidelidade'] = 1\n",
    "df_fidelidade.loc[df_fidelidade['fidelidade']=='nao', 'fidelidade'] = 0\n",
    "\n",
    "df_fidelidade['fidelidade'] = df_fidelidade['fidelidade'].astype('int64')\n",
    "\n",
    "df_fidelidade.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummizando as variáveis 'atendimento', 'sortimento', 'acessibilidade', 'preço' e 'sexo'. O código abaixo, automaticamente, fará:\n",
    "- a) a dummização das variáveis originais;\n",
    "- b) a remoção das variáveis dummizadas originais;\n",
    "- c) a definição das categorias de label 1 de cada variável original como categorias de referência, por meio do argumento 'drop_first=True'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fidelidade_dummies = pd.get_dummies(df_fidelidade,\n",
    "                                       columns=['atendimento',\n",
    "                                                'sortimento',\n",
    "                                                'acessibilidade',\n",
    "                                                'preço',\n",
    "                                                'sexo'],\n",
    "                                       dtype=int,\n",
    "                                       drop_first=True)\n",
    "\n",
    "df_fidelidade_dummies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimação do modelo logístico binário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sugestão de uso neste caso, dada a existência de muitas dummies no dataframe\n",
    "# Definição da fórmula utilizada no modelo\n",
    "\n",
    "lista_colunas = list(df_fidelidade_dummies.drop(columns=['id',\n",
    "                                                         'fidelidade']).columns)\n",
    "formula_dummies_modelo = ' + '.join(lista_colunas)\n",
    "formula_dummies_modelo = \"fidelidade ~ \" + formula_dummies_modelo\n",
    "print(\"Fórmula utilizada: \",formula_dummies_modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo propriamente dito\n",
    "modelo_fidelidade = sm.Logit.from_formula(formula_dummies_modelo,\n",
    "                                               df_fidelidade_dummies).fit()\n",
    "\n",
    "# Parâmetros do 'modelo_fidelidade'\n",
    "modelo_fidelidade.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procedimento Stepwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregamento da função 'stepwise' do pacote 'statstests.process'\n",
    "# Autores do pacote: Luiz Paulo Fávero e Helder Prado Santos\n",
    "# https://stats-tests.github.io/statstests/\n",
    "\n",
    "from statstests.process import stepwise\n",
    "\n",
    "#Estimação do modelo por meio do procedimento Stepwise\n",
    "step_modelo_fidelidade = stepwise(modelo_fidelidade, pvalue_limit=0.05)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construção de função para a definição da matriz de confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score,\\\n",
    "    ConfusionMatrixDisplay, recall_score\n",
    "\n",
    "def matriz_confusao(predicts, observado, cutoff):\n",
    "    \n",
    "    values = predicts.values\n",
    "    \n",
    "    predicao_binaria = []\n",
    "        \n",
    "    for item in values:\n",
    "        if item < cutoff:\n",
    "            predicao_binaria.append(0)\n",
    "        else:\n",
    "            predicao_binaria.append(1)\n",
    "           \n",
    "    cm = confusion_matrix(predicao_binaria, observado)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot()\n",
    "    plt.xlabel('True')\n",
    "    plt.ylabel('Classified')\n",
    "    plt.gca().invert_xaxis()\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.show()\n",
    "        \n",
    "    sensitividade = recall_score(observado, predicao_binaria, pos_label=1)\n",
    "    especificidade = recall_score(observado, predicao_binaria, pos_label=0)\n",
    "    acuracia = accuracy_score(observado, predicao_binaria)\n",
    "\n",
    "    #Visualizando os principais indicadores desta matriz de confusão\n",
    "    indicadores = pd.DataFrame({'Sensitividade':[sensitividade],\n",
    "                                'Especificidade':[especificidade],\n",
    "                                'Acurácia':[acuracia]})\n",
    "    return indicadores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construção da matriz de confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionando os valores previstos de probabilidade na base de dados\n",
    "df_fidelidade_dummies['phat'] = step_modelo_fidelidade.predict()\n",
    "\n",
    "# Matriz de confusão para cutoff = 0.5\n",
    "matriz_confusao(observado=df_fidelidade_dummies['fidelidade'],\n",
    "                predicts=df_fidelidade_dummies['phat'],\n",
    "                cutoff=0.50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Igualando critérios de especificidade e de sensitividade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tentaremos estabelecer um critério que iguale a probabilidade de\n",
    "#acerto daqueles que chegarão atrasados (sensitividade) e a probabilidade de\n",
    "#acerto daqueles que não chegarão atrasados (especificidade).\n",
    "\n",
    "# ATENÇÃO: o que será feito a seguir possui fins didáticos, apenas. DE NENHUMA\n",
    "#FORMA o procedimento garante a maximização da acurácia do modelo!\n",
    "\n",
    "# Criação da função 'espec_sens' para a construção de um dataset com diferentes\n",
    "#valores de cutoff, sensitividade e especificidade:\n",
    "\n",
    "def espec_sens(observado,predicts):\n",
    "    \n",
    "    # adicionar objeto com os valores dos predicts\n",
    "    values = predicts.values\n",
    "    \n",
    "    # range dos cutoffs a serem analisados em steps de 0.01\n",
    "    cutoffs = np.arange(0,1.01,0.01)\n",
    "    \n",
    "    # Listas que receberão os resultados de especificidade e sensitividade\n",
    "    lista_sensitividade = []\n",
    "    lista_especificidade = []\n",
    "    \n",
    "    for cutoff in cutoffs:\n",
    "        \n",
    "        predicao_binaria = []\n",
    "        \n",
    "        # Definindo resultado binário de acordo com o predict\n",
    "        for item in values:\n",
    "            if item >= cutoff:\n",
    "                predicao_binaria.append(1)\n",
    "            else:\n",
    "                predicao_binaria.append(0)\n",
    "                \n",
    "        # Cálculo da sensitividade e especificidade no cutoff\n",
    "        sensitividade = recall_score(observado, predicao_binaria, pos_label=1)\n",
    "        especificidadee = recall_score(observado, predicao_binaria, pos_label=0)\n",
    "        \n",
    "        # Adicionar valores nas listas\n",
    "        lista_sensitividade.append(sensitividade)\n",
    "        lista_especificidade.append(especificidadee)\n",
    "        \n",
    "    # Criar dataframe com os resultados nos seus respectivos cutoffs\n",
    "    resultado = pd.DataFrame({'cutoffs':cutoffs,'sensitividade':lista_sensitividade,'especificidade':lista_especificidade})\n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[3.10]: Até o momento, foram extraídos 3 vetores: 'sensitividade',\n",
    "#'especificidade' e 'cutoffs'. Assim, criamos um dataframe que contém\n",
    "#os vetores mencionados\n",
    "\n",
    "dados_plotagem = espec_sens(observado = df_fidelidade_dummies['fidelidade'],\n",
    "                            predicts = df_fidelidade_dummies['phat'])\n",
    "dados_plotagem.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[3.11]: Plotagem de um gráfico que mostra a variação da especificidade e da\n",
    "#sensitividade em função do cutoff\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "with plt.style.context('seaborn-v0_8-whitegrid'):\n",
    "    plt.plot(dados_plotagem.cutoffs,dados_plotagem.sensitividade, marker='o',\n",
    "         color='indigo', markersize=8)\n",
    "    plt.plot(dados_plotagem.cutoffs,dados_plotagem.especificidade, marker='o',\n",
    "         color='limegreen', markersize=8)\n",
    "plt.xlabel('Cuttoff', fontsize=20)\n",
    "plt.ylabel('Sensitividade / Especificidade', fontsize=20)\n",
    "plt.xticks(np.arange(0, 1.1, 0.2), fontsize=14)\n",
    "plt.yticks(np.arange(0, 1.1, 0.2), fontsize=14)\n",
    "plt.legend(['Sensitividade', 'Especificidade'], fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construção da curva ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função 'roc_curve' do pacote 'metrics' do sklearn\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "fpr, tpr, thresholds =roc_curve(df_fidelidade_dummies['fidelidade'],\n",
    "                                df_fidelidade_dummies['phat'])\n",
    "roc_auc = auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo do coeficiente de GINI\n",
    "gini = (roc_auc - 0.5)/(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotando a curva ROC\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.plot(fpr, tpr, marker='o', color='darkorchid', markersize=10, linewidth=3)\n",
    "plt.plot(fpr, fpr, color='gray', linestyle='dashed')\n",
    "plt.title('Área abaixo da curva: %g' % round(roc_auc, 4) +\n",
    "          ' | Coeficiente de GINI: %g' % round(gini, 4), fontsize=22)\n",
    "plt.xlabel('1 - Especificidade', fontsize=20)\n",
    "plt.ylabel('Sensitividade', fontsize=20)\n",
    "plt.xticks(np.arange(0, 1.1, 0.2), fontsize=14)\n",
    "plt.yticks(np.arange(0, 1.1, 0.2), fontsize=14)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usp_ds_analytics-M2oHMey2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
